{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl0qjCKamqBORsFaZioFYF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imy0ung/AI_Basic_Study/blob/main/model/linear_regression_file_input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tf-DimE3yLX",
        "outputId": "eb1db8ea-f666-4da0-9f8f-3b41272ce96a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 6 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (6/6), 28.74 KiB | 3.19 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/myunghakLee/data.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6FodOCrI342X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xy = np.loadtxt('/content/data/data-01-test-score.csv',delimiter=',',dtype=np.float32) # np의 loadtxt는 숫자형만 읽음\n",
        "x_data = xy[:,0:-1]\n",
        "y_data = xy[:,-1]\n",
        "\n",
        "print(x_data.shape, x_data, len(x_data))\n",
        "print(y_data.shape, y_data)\n",
        "\n",
        "x_data = torch.from_numpy(x_data)\n",
        "y_data = torch.from_numpy(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9FfwoFM4vF1",
        "outputId": "a8669e30-77dc-4868-cac8-51aa52318439"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25, 3) [[ 73.  80.  75.]\n",
            " [ 93.  88.  93.]\n",
            " [ 89.  91.  90.]\n",
            " [ 96.  98. 100.]\n",
            " [ 73.  66.  70.]\n",
            " [ 53.  46.  55.]\n",
            " [ 69.  74.  77.]\n",
            " [ 47.  56.  60.]\n",
            " [ 87.  79.  90.]\n",
            " [ 79.  70.  88.]\n",
            " [ 69.  70.  73.]\n",
            " [ 70.  65.  74.]\n",
            " [ 93.  95.  91.]\n",
            " [ 79.  80.  73.]\n",
            " [ 70.  73.  78.]\n",
            " [ 93.  89.  96.]\n",
            " [ 78.  75.  68.]\n",
            " [ 81.  90.  93.]\n",
            " [ 88.  92.  86.]\n",
            " [ 78.  83.  77.]\n",
            " [ 82.  86.  90.]\n",
            " [ 86.  82.  89.]\n",
            " [ 78.  83.  85.]\n",
            " [ 76.  83.  71.]\n",
            " [ 96.  93.  95.]] 25\n",
            "(25,) [152. 185. 180. 196. 142. 101. 149. 115. 175. 164. 141. 141. 184. 152.\n",
            " 148. 192. 147. 183. 177. 159. 177. 175. 175. 149. 192.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(nn.Module) :\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3,1,bias=True)\n",
        "\n",
        "  def forward(self,x) :\n",
        "    return self.linear(x)"
      ],
      "metadata": {
        "id": "t20Hx2WW70A1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearModel()\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = 0.00005)\n",
        "epochs = 1000"
      ],
      "metadata": {
        "id": "EvslW0r09jRk"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(epochs) :\n",
        "  prediction = model(x_data)\n",
        "  loss = criterion(prediction,y_data)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if step % 10 == 0 :\n",
        "    print (f\"epoch : {step}, loss : {loss.item():.4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WTKxg7-9wx7",
        "outputId": "b45303c4-0d83-4c3b-e179-76608f7cda4b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([25])) that is different to the input size (torch.Size([25, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0, loss : 1.056e+03\n",
            "epoch : 10, loss : 1.056e+03\n",
            "epoch : 20, loss : 1.056e+03\n",
            "epoch : 30, loss : 1.056e+03\n",
            "epoch : 40, loss : 1.056e+03\n",
            "epoch : 50, loss : 1.056e+03\n",
            "epoch : 60, loss : 1.056e+03\n",
            "epoch : 70, loss : 1.056e+03\n",
            "epoch : 80, loss : 1.056e+03\n",
            "epoch : 90, loss : 1.056e+03\n",
            "epoch : 100, loss : 1.056e+03\n",
            "epoch : 110, loss : 1.056e+03\n",
            "epoch : 120, loss : 1.056e+03\n",
            "epoch : 130, loss : 1.056e+03\n",
            "epoch : 140, loss : 1.056e+03\n",
            "epoch : 150, loss : 1.056e+03\n",
            "epoch : 160, loss : 1.056e+03\n",
            "epoch : 170, loss : 1.056e+03\n",
            "epoch : 180, loss : 1.056e+03\n",
            "epoch : 190, loss : 1.056e+03\n",
            "epoch : 200, loss : 1.056e+03\n",
            "epoch : 210, loss : 1.056e+03\n",
            "epoch : 220, loss : 1.056e+03\n",
            "epoch : 230, loss : 1.056e+03\n",
            "epoch : 240, loss : 1.056e+03\n",
            "epoch : 250, loss : 1.056e+03\n",
            "epoch : 260, loss : 1.056e+03\n",
            "epoch : 270, loss : 1.056e+03\n",
            "epoch : 280, loss : 1.055e+03\n",
            "epoch : 290, loss : 1.055e+03\n",
            "epoch : 300, loss : 1.055e+03\n",
            "epoch : 310, loss : 1.055e+03\n",
            "epoch : 320, loss : 1.055e+03\n",
            "epoch : 330, loss : 1.055e+03\n",
            "epoch : 340, loss : 1.055e+03\n",
            "epoch : 350, loss : 1.055e+03\n",
            "epoch : 360, loss : 1.055e+03\n",
            "epoch : 370, loss : 1.055e+03\n",
            "epoch : 380, loss : 1.055e+03\n",
            "epoch : 390, loss : 1.055e+03\n",
            "epoch : 400, loss : 1.055e+03\n",
            "epoch : 410, loss : 1.055e+03\n",
            "epoch : 420, loss : 1.055e+03\n",
            "epoch : 430, loss : 1.055e+03\n",
            "epoch : 440, loss : 1.055e+03\n",
            "epoch : 450, loss : 1.055e+03\n",
            "epoch : 460, loss : 1.055e+03\n",
            "epoch : 470, loss : 1.055e+03\n",
            "epoch : 480, loss : 1.055e+03\n",
            "epoch : 490, loss : 1.055e+03\n",
            "epoch : 500, loss : 1.055e+03\n",
            "epoch : 510, loss : 1.055e+03\n",
            "epoch : 520, loss : 1.055e+03\n",
            "epoch : 530, loss : 1.055e+03\n",
            "epoch : 540, loss : 1.055e+03\n",
            "epoch : 550, loss : 1.055e+03\n",
            "epoch : 560, loss : 1.055e+03\n",
            "epoch : 570, loss : 1.055e+03\n",
            "epoch : 580, loss : 1.055e+03\n",
            "epoch : 590, loss : 1.055e+03\n",
            "epoch : 600, loss : 1.055e+03\n",
            "epoch : 610, loss : 1.055e+03\n",
            "epoch : 620, loss : 1.055e+03\n",
            "epoch : 630, loss : 1.055e+03\n",
            "epoch : 640, loss : 1.055e+03\n",
            "epoch : 650, loss : 1.055e+03\n",
            "epoch : 660, loss : 1.055e+03\n",
            "epoch : 670, loss : 1.055e+03\n",
            "epoch : 680, loss : 1.055e+03\n",
            "epoch : 690, loss : 1.055e+03\n",
            "epoch : 700, loss : 1.055e+03\n",
            "epoch : 710, loss : 1.055e+03\n",
            "epoch : 720, loss : 1.055e+03\n",
            "epoch : 730, loss : 1.055e+03\n",
            "epoch : 740, loss : 1.055e+03\n",
            "epoch : 750, loss : 1.055e+03\n",
            "epoch : 760, loss : 1.055e+03\n",
            "epoch : 770, loss : 1.055e+03\n",
            "epoch : 780, loss : 1.055e+03\n",
            "epoch : 790, loss : 1.055e+03\n",
            "epoch : 800, loss : 1.054e+03\n",
            "epoch : 810, loss : 1.054e+03\n",
            "epoch : 820, loss : 1.054e+03\n",
            "epoch : 830, loss : 1.054e+03\n",
            "epoch : 840, loss : 1.054e+03\n",
            "epoch : 850, loss : 1.054e+03\n",
            "epoch : 860, loss : 1.054e+03\n",
            "epoch : 870, loss : 1.054e+03\n",
            "epoch : 880, loss : 1.054e+03\n",
            "epoch : 890, loss : 1.054e+03\n",
            "epoch : 900, loss : 1.054e+03\n",
            "epoch : 910, loss : 1.054e+03\n",
            "epoch : 920, loss : 1.054e+03\n",
            "epoch : 930, loss : 1.054e+03\n",
            "epoch : 940, loss : 1.054e+03\n",
            "epoch : 950, loss : 1.054e+03\n",
            "epoch : 960, loss : 1.054e+03\n",
            "epoch : 970, loss : 1.054e+03\n",
            "epoch : 980, loss : 1.054e+03\n",
            "epoch : 990, loss : 1.054e+03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model(torch.Tensor([[96.,93.,95.]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMohJeNG-UNO",
        "outputId": "95a43fb9-1936-4159-c103-65c41f0e97e6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[185.7888]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}